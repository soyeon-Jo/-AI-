{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 201712989 조소연\n",
    "# 빅데이터 분석 및 응용 개별 프로젝트 과제\n",
    "#### 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"It was well fought,\" he said, \"and, by my soo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Not to pay him was impossible, considering his...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>“A proper figure of a man at-arms,” said the l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>'You were not here last Sunday night,' he said.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>“You must not ask me that!” I cried. “Hell may...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  author\n",
       "0      0  He was almost choking. There was so much, so m...       3\n",
       "1      1             “Your sister asked for it, I suppose?”       2\n",
       "2      2   She was engaged one day as she walked, in per...       1\n",
       "3      3  The captain was in the porch, keeping himself ...       4\n",
       "4      4  “Have mercy, gentlemen!” odin flung up his han...       3\n",
       "5      5  \"It was well fought,\" he said, \"and, by my soo...       4\n",
       "6      6  Not to pay him was impossible, considering his...       3\n",
       "7      7  “A proper figure of a man at-arms,” said the l...       2\n",
       "8      8    'You were not here last Sunday night,' he said.       0\n",
       "9      9  “You must not ask me that!” I cried. “Hell may...       4"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10) #데이터 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54879, 3)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    15063\n",
       "0    13235\n",
       "2    11554\n",
       "4     7805\n",
       "1     7222\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test 분류\n",
    "train set과 test set을 3:1로 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.text,df.author,test_size=0.1,random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49391,)\n",
      "(49391,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5488,)\n",
      "(5488,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카운트 기반 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (49391, 2000)\n",
      "Test set dimension: (5488, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5).fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train) \n",
    "print('Train set dimension:', X_train_cv.shape) \n",
    "X_test_cv = cv.transform(X_test)\n",
    "print('Test set dimension:', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_features, min_df, max_df** 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_i_ : 0, _that_ : 0, _you_ : 0, able : 0, about : 0, above : 0, abroad : 0, absence : 0, absolutely : 0, absurd : 0, accept : 0, accepted : 0, accident : 0, according : 0, account : 0, acquaintance : 0, acquainted : 0, across : 0, act : 0, action : 0, actually : 0, add : 0, added : 0, address : 0, addressed : 0, addressing : 0, admiration : 0, admit : 0, admitted : 0, advance : 0, advanced : 0, advantage : 0, adventure : 0, advice : 0, affair : 0, affairs : 0, affected : 0, affection : 0, afraid : 0, after : 0, afternoon : 0, afterwards : 0, again : 0, against : 0, age : 0, agitated : 0, agitation : 0, ago : 0, agree : 0, agreeable : 0, agreed : 0, ah : 0, ain : 0, air : 0, alarm : 0, alarmed : 0, alas : 0, alive : 0, all : 0, allow : 0, allowed : 0, almost : 0, alone : 0, along : 0, aloud : 0, already : 0, also : 0, although : 0, altogether : 0, always : 0, am : 0, amazement : 0, america : 0, amiable : 0, among : 0, an : 0, angel : 0, anger : 0, angrily : 0, angry : 0, anne : 0, another : 0, answer : 0, answered : 0, anxiety : 0, anxious : 0, any : 0, anybody : 0, anyone : 0, anything : 0, anyway : 0, anywhere : 0, apart : 0, apparently : 0, appear : 0, appearance : 0, appeared : 0, appears : 0, approached : 0, approaching : 0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(cv.get_feature_names()[:100], X_train_cv[0].toarray()[0,:100]):\n",
    "    print(word, ':', count, end=', ')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브베이즈를 이용한 문서분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.667\n",
      "Test set score: 0.644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제작가, 예측한 작가, text\n",
      "(3, 3, '“But I thought at the time that you quite guessed,” odin parried with the simplest air.')\n",
      "(2, 0, '“The treasure is lost,” said Miss odin, calmly.')\n",
      "(0, 0, \"“You don't hear much about them now?” said the spy.\")\n",
      "(0, 2, \"'odin,' said odin, abruptly breaking the stillness that prevailed; 'is it worth fifty shiners extra, if it's safely done from the outside?'\")\n",
      "(1, 1, 'The subject was continued no farther; and odin remained thoughtfully silent, till a new object suddenly engaged her attention. She was sitting by odin, and in taking his tea from Mrs. odin, his hand passed so directly before her, as to make a ring, with a plait of hair in the centre, very conspicuous on one of his fingers.')\n",
      "(3, 3, 'The prince’s tone was so natural and respectful that the general could not possibly suspect him of any insincerity.')\n",
      "(2, 3, '“Here are three more,” said odin.')\n",
      "(3, 3, 'She sank helplessly on the bed with her face in the pillows, but a moment later she got up, moved quickly to him, seized both his hands and, gripping them tight in her thin fingers, began looking into his face again with the same intent stare. In this last desperate look she tried to look into him and catch some last hope. But there was no hope; there was no doubt remaining; it was all true! Later on, indeed, when she recalled that moment, she thought it strange and wondered why she had seen at once that there was no doubt. She could not have said, for instance, that she had foreseen something of the sort--and yet now, as soon as he told her, she suddenly fancied that she had really foreseen this very thing.')\n",
      "(3, 3, 'odin waited a moment and then began. \"I\\'ve heard that you have some influence on odin, and that she was fond of seeing you and hearing you talk. Is that so?\"')\n",
      "(3, 3, '“So much for your money! So much for your money! So much for your money! So much for your money!”')\n"
     ]
    }
   ],
   "source": [
    "print('실제작가, 예측한 작가, text')\n",
    "for content in zip(y_test[:10], NB_clf.predict(X_test_cv[:10]), X_test[:10]):\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer 대신 TfidfVectorizer 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.667\n",
      "Test set score: 0.645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5).fit(X_train) \n",
    "X_train_tfidf = tfidf.transform(X_train) \n",
    "X_test_tfidf = tfidf.transform(X_test) \n",
    "\n",
    "NB_clf.fit(X_train_tfidf, y_train) \n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set 예측정확도\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set 예측정확도\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 로지스틱 회귀분석을 이용한 문서 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.724\n",
      "Test set score: 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "#count vector에 대해 regression을 해서 NB와 비교\n",
    "LR_clf = LogisticRegression() \n",
    "LR_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))  \n",
    "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제작가, 예측한 작가, text\n",
      "(3, 3, '“But I thought at the time that you quite guessed,” odin parried with the simplest air.')\n",
      "(2, 0, '“The treasure is lost,” said Miss odin, calmly.')\n",
      "(0, 0, \"“You don't hear much about them now?” said the spy.\")\n",
      "(0, 2, \"'odin,' said odin, abruptly breaking the stillness that prevailed; 'is it worth fifty shiners extra, if it's safely done from the outside?'\")\n",
      "(1, 4, 'The subject was continued no farther; and odin remained thoughtfully silent, till a new object suddenly engaged her attention. She was sitting by odin, and in taking his tea from Mrs. odin, his hand passed so directly before her, as to make a ring, with a plait of hair in the centre, very conspicuous on one of his fingers.')\n",
      "(3, 1, 'The prince’s tone was so natural and respectful that the general could not possibly suspect him of any insincerity.')\n",
      "(2, 2, '“Here are three more,” said odin.')\n",
      "(3, 4, 'She sank helplessly on the bed with her face in the pillows, but a moment later she got up, moved quickly to him, seized both his hands and, gripping them tight in her thin fingers, began looking into his face again with the same intent stare. In this last desperate look she tried to look into him and catch some last hope. But there was no hope; there was no doubt remaining; it was all true! Later on, indeed, when she recalled that moment, she thought it strange and wondered why she had seen at once that there was no doubt. She could not have said, for instance, that she had foreseen something of the sort--and yet now, as soon as he told her, she suddenly fancied that she had really foreseen this very thing.')\n",
      "(3, 0, 'odin waited a moment and then began. \"I\\'ve heard that you have some influence on odin, and that she was fond of seeing you and hearing you talk. Is that so?\"')\n",
      "(3, 2, '“So much for your money! So much for your money! So much for your money! So much for your money!”')\n"
     ]
    }
   ],
   "source": [
    "print('실제작가, 예측한 작가, text')\n",
    "for content in zip(y_test[:10], LR_clf.predict(X_test_cv[:10]), X_test[:10]):\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 릿지 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.711\n",
      "Test set score: 0.669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, y_train) \n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha를 조절하여 다시 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.712\n",
      "Test set score: 0.670\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha=1.6) #릿지 분류기 선언\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.711\n",
      "Test set score: 0.670\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha=1.9)\n",
    "ridge_clf.fit(X_train_tfidf, y_train) \n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라쏘 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.720\n",
      "#Test set score: 0.684\n",
      "#Used features count: 6161 out of 2000\n"
     ]
    }
   ],
   "source": [
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1) \n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.693\n",
      "#Test set score: 0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 필요한 library들을 import\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
    "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower()) #이렇게 해도 되는지 확인\n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    # portr stemmer 적용\n",
    "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
    "    return features\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5) # 새로 정의한 토크나이저 사용\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "\n",
    "#tfidf vector를 이용해서 분류기 학습\n",
    "LR_clf = LogisticRegression() #분류기 선언\n",
    "LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set dimension: (49391, 21840)\n",
      "#Test set dimension: (5488, 21840)\n",
      "#Train set score: 0.816\n",
      "#Test set score: 0.733\n",
      "#Train set score: 0.805\n",
      "#Test set score: 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer).fit(X_train) \n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train) # train set을 변환\n",
    "print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "print('#Test set dimension:', X_test_tfidf.shape)\n",
    "\n",
    "ridge_clf = RidgeClassifier(alpha=2.4)\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('#Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언\n",
    "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **나이브베이즈**\n",
    "<br>Train set score: 0.667\n",
    "<br>Test set score: 0.644\n",
    "- **tfidf**\n",
    "<br>Train set score: 0.667\n",
    "<br>Test set score: 0.645\n",
    "- **tfidf 성능조절(불용어 제거, 스테머, Regexp)**\n",
    "<br>Train set score: 0.693\n",
    "<br>Test set score: 0.648\n",
    "- **로지스틱**\n",
    "<br>Train set score: 0.724\n",
    "<br>Test set score: 0.686\n",
    "- **릿지**\n",
    "<br>Train set score: 0.711\n",
    "<br>Test set score: 0.669\n",
    "- **알파를 조절한 릿지**\n",
    "<br>Train set score: 0.711\n",
    "<br>Test set score: 0.670\n",
    "- **라쏘**\n",
    "<br>Train set score: 0.720\n",
    "<br>Test set score: 0.684\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체적으로 Train set score가 Test set score보다 높은 것을 알 수 있다.<br>\n",
    "나이브 베이즈와 tfidf는 Train set score: 0.667,Test set score: 0.644와 Train set score: 0.667, Test set score: 0.645로 성능에 큰 사이는 없다.<br>\n",
    "tfidf에 불용어 제거, 스테머 적용, Regexp를 적용해 보았을 때에는 오히려 성능이 좋아졌다는 점수로 생각하기 어렵다.<br>\n",
    " 이어서, 로지스틱분석 Train set score: 0.724, Test set score: 0.686로 전체적 점수는 나이브 베이즈와 , tfidf보다 높지만 Train set과 Test set의 차이가 비교적 크다.<br>\n",
    " 다음으로 릿지회귀는 Train set score: 0.711, Test set score: 0.669로 로지스틱 회귀보다 그 점수가 떨어지졌다. 알파를 이리저리 조절해보았을 때에도 최적 알파값은 1.9로 Test set score이 0.001정도 높아졌다. 그래도 제일 좋은 모형이라고 생각할 수 없다.<br>\n",
    " 마지막으로 라쏘 회귀에서는 Train set score: 0.720, Test set score: 0.684이다.\n",
    " <br>\n",
    " 모든 모형을 비교해보았을 때 점수가 제일 높은 로지스틱 회귀가 0.724와 0.686으로 가장 좋은 결과를 얻을 수 있는 모형이라고 할 수 있다. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
